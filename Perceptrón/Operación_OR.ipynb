{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNxAK7U8JLX1xcUIdHFTVSd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sergio191699-ship-it/mi-repositorio_tarea1/blob/main/Perceptr%C3%B3n/Operaci%C3%B3n_OR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d5y3dIb7jcsU"
      },
      "outputs": [],
      "source": [
        "Operación_OR"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class Perceptron:\n",
        "    def __init__(self, tasa_aprendizaje=0.1, n_entradas=2, max_epocas=100):\n",
        "        self.eta = tasa_aprendizaje\n",
        "        self.max_epocas = max_epocas\n",
        "        self.pesos = np.random.rand(n_entradas + 1) * 0.1\n",
        "\n",
        "    def activacion(self, x):\n",
        "        return 1 if x >= 0 else 0\n",
        "\n",
        "    def predict(self, entradas):\n",
        "        suma = np.dot(entradas, self.pesos[1:]) + self.pesos[0]\n",
        "        return self.activacion(suma)\n",
        "\n",
        "    def entrenar(self, X, y):\n",
        "        print(\"=== ENTRENANDO PERCEPTRÓN PARA OPERACIÓN OR ===\")\n",
        "        print(f\"Tasa de aprendizaje (η): {self.eta}\")\n",
        "        print(f\"Pesos iniciales: w0(bias)={self.pesos[0]:.3f}, w1={self.pesos[1]:.3f}, w2={self.pesos[2]:.3f}\")\n",
        "        print(\"\\nComienza entrenamiento...\")\n",
        "        print(\"-\" * 60)\n",
        "\n",
        "        for epoca in range(self.max_epocas):\n",
        "            errores = 0\n",
        "            for entradas, objetivo in zip(X, y):\n",
        "                prediccion = self.predict(entradas)\n",
        "                error = objetivo - prediccion\n",
        "                if error != 0:\n",
        "                    self.pesos[1:] += self.eta * error * entradas\n",
        "                    self.pesos[0] += self.eta * error\n",
        "                    errores += 1\n",
        "\n",
        "            if (epoca + 1) % 10 == 0 or epoca == 0:\n",
        "                print(f\"Época {epoca + 1:3d}: Errores = {errores}\")\n",
        "\n",
        "            if errores == 0:\n",
        "                print(f\"\\n✅ Convergencia alcanzada en la época {epoca + 1}\")\n",
        "                break\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"RESULTADOS DEL ENTRENAMIENTO:\")\n",
        "        print(f\"Pesos finales: w0(bias)={self.pesos[0]:.3f}, w1={self.pesos[1]:.3f}, w2={self.pesos[2]:.3f}\")\n",
        "        return\n",
        "\n",
        "# Datos de entrenamiento para OR\n",
        "X_entrenamiento = np.array([\n",
        "    [0, 0],\n",
        "    [0, 1],\n",
        "    [1, 0],\n",
        "    [1, 1]\n",
        "])\n",
        "y_objetivo = np.array([0, 1, 1, 1])\n",
        "\n",
        "# Crear y entrenar perceptrón\n",
        "perceptron_or = Perceptron(tasa_aprendizaje=0.1, n_entradas=2, max_epocas=50)\n",
        "perceptron_or.entrenar(X_entrenamiento, y_objetivo)\n",
        "\n",
        "# Probar el perceptrón entrenado\n",
        "print(\"\\n=== PRUEBA FINAL ===\")\n",
        "print(\"Entradas | Salida OR | Predicción\")\n",
        "print(\"---------+-----------+------------\")\n",
        "\n",
        "for entrada in X_entrenamiento:\n",
        "    objetivo = 1 if (entrada[0] or entrada[1]) else 0\n",
        "    prediccion = perceptron_or.predict(entrada)\n",
        "    estado = \"✅\" if prediccion == objetivo else \"❌\"\n",
        "    print(f\"  ({entrada[0]},{entrada[1]})   |     {objetivo}     |     {prediccion}      {estado}\")\n",
        "\n",
        "# Mostrar la función aprendida\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"FUNCIÓN APRENDIDA POR EL PERCEPTRÓN:\")\n",
        "print(f\"y = 1 si [{perceptron_or.pesos[1]:.3f}*x1 + {perceptron_or.pesos[2]:.3f}*x2 + {perceptron_or.pesos[0]:.3f}] ≥ 0\")\n",
        "print(f\"y = 0 en caso contrario\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jkuet8-j6WN",
        "outputId": "5570a4c3-88c2-4ffc-d76b-f00ab5ff6a28"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== ENTRENANDO PERCEPTRÓN PARA OPERACIÓN OR ===\n",
            "Tasa de aprendizaje (η): 0.1\n",
            "Pesos iniciales: w0(bias)=0.066, w1=0.057, w2=0.020\n",
            "\n",
            "Comienza entrenamiento...\n",
            "------------------------------------------------------------\n",
            "Época   1: Errores = 2\n",
            "\n",
            "✅ Convergencia alcanzada en la época 3\n",
            "\n",
            "============================================================\n",
            "RESULTADOS DEL ENTRENAMIENTO:\n",
            "Pesos finales: w0(bias)=-0.034, w1=0.057, w2=0.120\n",
            "\n",
            "=== PRUEBA FINAL ===\n",
            "Entradas | Salida OR | Predicción\n",
            "---------+-----------+------------\n",
            "  (0,0)   |     0     |     0      ✅\n",
            "  (0,1)   |     1     |     1      ✅\n",
            "  (1,0)   |     1     |     1      ✅\n",
            "  (1,1)   |     1     |     1      ✅\n",
            "\n",
            "============================================================\n",
            "FUNCIÓN APRENDIDA POR EL PERCEPTRÓN:\n",
            "y = 1 si [0.057*x1 + 0.120*x2 + -0.034] ≥ 0\n",
            "y = 0 en caso contrario\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "¿QUÉ ESTÁ HACIENDO EL PERCEPTRÓN EN LA OPERACIÓN OR?\n",
        "\n",
        "En este caso, el Perceptrón básicamente está aprendiendo por su cuenta cómo funciona la operación OR. A diferencia del modelo de McCulloch-Pitts, donde nosotros mismos decidimos qué valores deben tener los pesos, aquí el Perceptrón empieza con pesos pequeños elegidos al azar (más un bias) y va corrigiéndose a medida que ve ejemplos.\n",
        "\n",
        "El proceso es bastante intuitivo: le mostramos todas las combinaciones posibles de 0 y 1 junto con el resultado correcto de OR. Con cada ejemplo, el Perceptrón calcula una salida usando los pesos que tiene en ese momento y la compara con lo que debería haber dado. Si se equivoca, ajusta los pesos usando la famosa regla de actualización. Y así, una y otra vez, durante varias “vueltas” o épocas, hasta que deja de fallar.\n",
        "\n",
        "La tasa de aprendizaje, η, es simplemente un número que controla qué tan fuerte se ajustan los pesos cada vez que hay un error. Si es pequeña, aprende más despacio; si es grande, puede que se descontrole un poco.\n",
        "\n",
        "Algo importante es que la operación OR es un problema linealmente separable, lo que significa que sí existe una línea que separa las entradas que producen un 0 de las que producen un 1. Por eso el Perceptrón tiene garantizado encontrar esa solución.\n",
        "\n",
        "En pocas palabras, esta neurona termina aprendiendo sola a encenderse cuando al menos una entrada vale 1, sin que nosotros tengamos que decirle exactamente cómo lograrlo."
      ],
      "metadata": {
        "id": "l9J-xeZ0oUSO"
      }
    }
  ]
}