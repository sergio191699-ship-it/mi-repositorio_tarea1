{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOj/pEHt9Kx6DkLGZ7mTV+4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sergio191699-ship-it/mi-repositorio_tarea1/blob/main/Perceptr%C3%B3n/Operaci%C3%B3n_NOT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Operación_NOT"
      ],
      "metadata": {
        "id": "UbGsDzQWltaW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PaCztz8Jlsv-",
        "outputId": "15b87411-2de3-4b24-b8af-95e747d1b3ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== ENTRENANDO PERCEPTRÓN PARA OPERACIÓN NOT ===\n",
            "Tasa de aprendizaje (η): 0.1\n",
            "Parámetros iniciales: peso=0.030, bias=0.049\n",
            "\n",
            "Comienza entrenamiento...\n",
            "------------------------------------------------------------\n",
            "Época   1: Errores = 1\n",
            "\n",
            "✅ Convergencia alcanzada en la época 3\n",
            "\n",
            "============================================================\n",
            "RESULTADOS DEL ENTRENAMIENTO:\n",
            "Parámetros finales: peso=-0.070, bias=0.049\n",
            "\n",
            "=== PRUEBA FINAL ===\n",
            "Entrada | Salida NOT | Predicción\n",
            "--------+------------+------------\n",
            "   0    |     1      |     1       ✅\n",
            "   1    |     0      |     0       ✅\n",
            "\n",
            "============================================================\n",
            "FUNCIÓN APRENDIDA POR EL PERCEPTRÓN:\n",
            "y = 1 si [-0.070*x + 0.049] ≥ 0\n",
            "y = 0 en caso contrario\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "class PerceptronNOT:\n",
        "    def __init__(self, tasa_aprendizaje=0.1, max_epocas=100):\n",
        "        self.eta = tasa_aprendizaje\n",
        "        self.max_epocas = max_epocas\n",
        "        self.peso = np.random.rand() * 0.1\n",
        "        self.bias = np.random.rand() * 0.1\n",
        "\n",
        "    def activacion(self, x):\n",
        "        return 1 if x >= 0 else 0\n",
        "\n",
        "    def predict(self, entrada):\n",
        "        suma = self.peso * entrada + self.bias\n",
        "        return self.activacion(suma)\n",
        "\n",
        "    def entrenar(self, X, y):\n",
        "        print(\"=== ENTRENANDO PERCEPTRÓN PARA OPERACIÓN NOT ===\")\n",
        "        print(f\"Tasa de aprendizaje (η): {self.eta}\")\n",
        "        print(f\"Parámetros iniciales: peso={self.peso:.3f}, bias={self.bias:.3f}\")\n",
        "        print(\"\\nComienza entrenamiento...\")\n",
        "        print(\"-\" * 60)\n",
        "\n",
        "        for epoca in range(self.max_epocas):\n",
        "            errores = 0\n",
        "            for entrada, objetivo in zip(X, y):\n",
        "                prediccion = self.predict(entrada)\n",
        "                error = objetivo - prediccion\n",
        "                if error != 0:\n",
        "                    self.peso += self.eta * error * entrada\n",
        "                    self.bias += self.eta * error\n",
        "                    errores += 1\n",
        "\n",
        "            if (epoca + 1) % 10 == 0 or epoca == 0:\n",
        "                print(f\"Época {epoca + 1:3d}: Errores = {errores}\")\n",
        "\n",
        "            if errores == 0:\n",
        "                print(f\"\\n✅ Convergencia alcanzada en la época {epoca + 1}\")\n",
        "                break\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"RESULTADOS DEL ENTRENAMIENTO:\")\n",
        "        print(f\"Parámetros finales: peso={self.peso:.3f}, bias={self.bias:.3f}\")\n",
        "        return\n",
        "\n",
        "# Datos de entrenamiento para NOT\n",
        "X_entrenamiento = np.array([0, 1])\n",
        "y_objetivo = np.array([1, 0])\n",
        "\n",
        "# Crear y entrenar perceptrón\n",
        "perceptron_not = PerceptronNOT(tasa_aprendizaje=0.1, max_epocas=50)\n",
        "perceptron_not.entrenar(X_entrenamiento, y_objetivo)\n",
        "\n",
        "# Probar el perceptrón entrenado\n",
        "print(\"\\n=== PRUEBA FINAL ===\")\n",
        "print(\"Entrada | Salida NOT | Predicción\")\n",
        "print(\"--------+------------+------------\")\n",
        "\n",
        "for entrada in X_entrenamiento:\n",
        "    objetivo = 0 if entrada == 1 else 1\n",
        "    prediccion = perceptron_not.predict(entrada)\n",
        "    estado = \"✅\" if prediccion == objetivo else \"❌\"\n",
        "    print(f\"   {entrada}    |     {objetivo}      |     {prediccion}       {estado}\")\n",
        "\n",
        "# Mostrar la función aprendida\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"FUNCIÓN APRENDIDA POR EL PERCEPTRÓN:\")\n",
        "print(f\"y = 1 si [{perceptron_not.peso:.3f}*x + {perceptron_not.bias:.3f}] ≥ 0\")\n",
        "print(f\"y = 0 en caso contrario\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "¿QUÉ ESTÁ HACIENDO EL PERCEPTRÓN EN LA OPERACIÓN NOT?\n",
        "\n",
        "En este caso, el Perceptrón está aprendiendo a funcionar como un negador lógico, es decir, a devolver lo contrario de lo que recibe. A diferencia de la operación OR, aquí solo hay una entrada, así que el proceso es más directo. El Perceptrón empieza con un peso y un bias elegidos al azar y se entrena únicamente con dos ejemplos muy simples: cuando la entrada es 0, la salida correcta debería ser 1, y cuando la entrada es 1, la salida debería ser 0.\n",
        "\n",
        "En cada intento, el modelo calcula una salida usando los valores actuales, la compara con lo que debería haber dado y luego ajusta tanto el peso como el bias en función del error que cometió. Con este proceso repetitivo, el Perceptrón termina descubriendo por sí mismo que necesita un peso negativo, aproximadamente de -1, y un bias positivo cercano a 0.5 para comportarse correctamente como un NOT. Y esto tiene sentido: cuando la entrada es 0, el resultado que obtiene es positivo y por eso devuelve un 1; cuando la entrada es 1, el resultado se vuelve negativo y la salida es 0.\n",
        "\n",
        "Este pequeño ejemplo muestra cómo el Perceptrón puede aprender incluso una operación tan simple como la negación sin que tengamos que decirle explícitamente qué fórmula usar. También deja claro que el bias es fundamental para definir el punto donde decide si la salida será un 0 o un 1."
      ],
      "metadata": {
        "id": "cIspFTevohQO"
      }
    }
  ]
}